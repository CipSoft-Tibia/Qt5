#------------------------------------------------------------------------------
# neuralnet.cfg
#
# Configuration file for Neural Net Classification Method for
# Lipi Toolkit 4.0.0
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# The standard format for the configuration entries is the name of the 
# configuration parameter seperated by an equal to sign and then the value of 
# the configuration parameter. For example:
# ConfigurationEntryName = value
#
# Lines starting with a # are commnet lines
#
# A cfg entry is strictly a key value pair and leaving the key without the 
# value or specification of a value out of the range is not permitted
#
# If a cfg entry is not specified at all, then default values are used by the 
# recognizer
#------------------------------------------------------------------------------ 

#-------------------------------
#	PREPROCESSING	
#-------------------------------

#-------------------------------------------------------------------------------
# ResampTraceDimension
#
# Description: The number of target points for resampling. In other words, 
# each character will be resampled to this number of points. In case of 
# multistroke characters, this number of points will be distributed between 
# the strokes in proportion to their lengths in proportion to their initial 
# number of points.  
#
# Valid values: Any integer > 0
# Units: Points
# Default value: 60
# Typical value: Average number of points per character in the training data set.
#-------------------------------------------------------------------------------
ResampTraceDimension = 60


#-------------------------------------------------------------------------------
# ResampPointAllocation
#
# Description: Method to be used for point allocation among different strokes 
# during resampling. Two schemes have been implemented lengthbased and point 
# based. In lengthbased allocation scheme, the number of points allocated to 
# each stroke is proportional to the length of the stroke. Length of a stroke 
# is calculated as the sum of the distances between each point in the stroke. 
# In the pointbased allocation scheme, the target stroke point allocation is 
# proportional to the number of points in the initial stroke. In the 
# interpointdistbased scheme, the distance between consecutive points is fixed 
# resulting in variable number based on the length of the trajectory.
# 
# Valid value: [lengthbased | pointbased | interpointdistbased]
# Default value: lengthbased
#-------------------------------------------------------------------------------
ResampPointAllocation = lengthbased

#-------------------------------------------------------------------------------
# NormDotSizeThreshold
#
# Description: This threshold is used to determine whether a character is a dot.
# It is expressed in real length terms (inches) and converted internally to
# points using knowledge of the device’s spatial resolution. If the width 
# and height are both less than this threshold, then all the points are replaced
# with the center of the of the normalized character, basically to represent it 
# as a dot
#
# Valid values: Any real number > 0
# Units: inches
# Default value: 0.01
# Typical value: < 0.1 
#-------------------------------------------------------------------------------
NormDotSizeThreshold = 0.00001

#-------------------------------------------------------------------------------
# NormLineWidthThreshold
#
# Description: This threshold is used to detect whether the character is a 
# vertical or horizontal line. If only the height is less than this threshold 
# then the character is detected as a horizontal line and if only the width is 
# less than this threshold then the character is detected as a vertical line. 
# Assuming the height is along the y-dimension and width is along the x-
# dimension, during normalization of a horizontal line only the x-coordinates 
# are scaled and the y-coordinates are translated to the center of the character, 
# with out scaling. Similarly for the vertical line only the y-coordinates are 
# normalized and the x-coordinates are translated to the center with out scaling
#
# Valid values: Any real number > 0
# Units: inches
# Default value: 0.01
# Typical value: < 0.1 
#-------------------------------------------------------------------------------
NormLineWidthThreshold = 0.01

#-------------------------------------------------------------------------------
# NormPreserveAspectRatio
#
# Description: This parameter is used to indicate whether the aspect ratio 
# has to be preserved during normalization. The aspect ratio is the calculated 
# as maximum of (height/width , width/height). The aspect ratio is preserved only 
# if the calculated aspect ratio is greater than the threshold value specified 
# through NormPreserveAspectRatioThreshold and this configuration variable is 
# set to true. If this configuration variable is set to false the aspect ratio 
# is not preserved during normalization.
# 
# Valid value: [true | false]
# Default value: true
#-------------------------------------------------------------------------------
NormPreserveAspectRatio = true


#-------------------------------------------------------------------------------
# NormPreserveAspectRatioThreshold
#
# Description: Aspect ratio is preserved during normalization if the computed 
# aspect ratio (max(height/width, width/height)) is greater than this threshold 
# and the configuration value NormPreserveAspectRatio is set to true. During 
# aspect ratio preserving normalization, the larger of the two dimensions is 
# normalized to the standard size and the other dimension is normalized 
# proportional to the initial height and width ratio, so that the initial 
# aspect ratio is maintained.
#
# Valid values: Any real number >= 1
# Default value: 3
# Typical value: >= 1.5
#------------------------------------------------------------------------------- 
NormPreserveAspectRatioThreshold = 3

#-------------------------------------------------------------------------------
# NormPreserveRelativeYPosition
#
# Description: The relative Y position is the mean of the y-coordinates in the 
# input character. During normalization if this parameter is set to true, each 
# y-coordinate of the character point is translated by the initial y-mean value, 
# so that the mean of the y-coordinates remains the same before and after  
# normalization. This is typically used in the word recognition context where 
# each stroke of the character has to be normalized separately and the relative 
# position of the strokes should be maintained even after normalization. 
# 
# Valid value: [true | false]
# Default value: false
#------------------------------------------------------------------------------- 
NormPreserveRelativeYPosition = false

#-------------------------------------------------------------------------------
# SmoothWindowSize
#
# Description: The configuration value specifies the length of the moving 
# average filter (size of the window) for smoothing the character image.
# If this value is set to N, then each point in the input character is replaced
# by the average of value of this point, (N-1)/2 points on the right and (N-1)/2
# on the left of this point.
#
# Valid value: Any integer > 0
# Units: Points
# Typical value: 5
# Default value: 3
#-------------------------------------------------------------------------------
SmoothWindowSize = 3

#-------------------------------------------------------------------------------
# PreprocSequence
# 
# Description: This variable is used to specify the sequence of preprocessing
# operations to be carried out on the input character sample before extracting 
# the features. A valid preprocessing sequence can consist of combination of one 
# or more of the functions selected from the valid values set mentioned below. 
# The CommonPreProc prefix is used specify the default preprocessing module of 
# LipiTk. The user can add his own preprocessing functions in other modules and 
# specify them in the preprocessing sequence.
#
# Valid values: Any sequence formed from the following set
# CommonPreProc::normalizeSize;
# CommonPreProc::removeDuplicatePoints;
# CommonPreProc::smoothenTraceGroup;
# CommonPreProc::dehookTraces;
# CommonPreProc::normalizeOrientation;
# CommonPreProc::resampleTraceGroup;
# Default value: {CommonPreProc::normalizeSize,CommonPreProc::resampleTraceGroup,CommonPreProc::normalizeSize}
#-------------------------------------------------------------------------------
PreprocSequence={CommonPreProc::normalizeSize,CommonPreProc::resampleTraceGroup,CommonPreProc::normalizeSize}

#---------------------------------------
#	TRAINING
#---------------------------------------

#-------------------------------------------------------------------------------
# SeedValueForRandomNumberGenaretor
#
# Description: The generation of pseudo-random numbers is a common task in computer
# simulations. Computational algorithms (pseudorandom number generators) producing
# pseudo-random numbers (sequences of apparently random numbers), are in fact
# completely determined by a shorter initial value, called a seed or key. Any integer
# value can be used for this seed. Different values of seed should produce different
# sequences of pseudo-random numbers depending upon the periodicity of the generating
# algorithm. This quantity is used to initialise the random number generator. Random
# numbers are used to initialize connection weights of the network. Different seed
# values should produce different sequences of pseudo-random numbers depending upon
# the periodicity of the generating algorithm.
#
# Valid value: [Any integer > 0] 
# Default value: 426
#-------------------------------------------------------------------------------
SeedValueForRandomNumberGenaretor = 456

#-------------------------------------------------------------------------------
# NormalizationFactor
#
# Description: Input feature components are divided by this quatity because present
# implementation of BackPropagation algorithm needs input feature vector components
# in the range 0 to 1. Usually, this quantity is greater than or equal to the possible
# maximum value of input feature components. 
#
# Valid value: [Any real number grater then 0.0] 
# Default value: 10.0
#-------------------------------------------------------------------------------
NeuralNetNormalizationFactor = 10.0

#-------------------------------------------------------------------------------
# NeuralNetLearningRate
#
# Description: This is the parameter of the learning algorithm that controls step size along
# the steepest descent in the error (system error) surface. Connection weights are adjusted
# by adding the weight increment multiplied by this quantity to the previous weight. The
# learning rate indicates how far in the direction of steepest descent the network weights are
# shifted at each iteration. For example, if this value is 1.0, the shift amount will be equal
# to the value of the resultant gradient. For parctical problem in which the error surface is
# generally nonlinear, a smaller learning rate must be used to slowly and smoothly guide the
# descent towards the optimum weights; therefore, this value is normally between 0 and 1, and
# indicates the proportion of the gradient length that will be traversed in the direction of the
# steepest descent.
# 
# Valid value: Any real number from 0-1
# Default value: 0.005
#-------------------------------------------------------------------------------
NeuralNetLearningRate = 0.005

#-------------------------------------------------------------------------------
# NeuralNetMomemtumRate
#
# Description: A quantity involving momentum rate was introduced in the weight modification 
# rule of BackPropagation algorithm for incorporating influence of the past iterations during
# current updation of the connection weights.  The momentum introduces a "damping" effect on 
# the search procedure, thus avoiding possible oscillations on the error surface by averaging 
# gradient components with opposite sign and accelerating the convergence in long flat areas. 
# Also, in situations of falling into local minima, it possibly helps to certain limit to avoid 
# the same. Momentum may be considered as an approximation to a second-order method, as it uses 
# information from the previous iterations.
# 
# Valid value: Any real number from 0-1
# Default value: 0.0025
#-------------------------------------------------------------------------------
NeuralNetMomemtumRate = 0.0025

#-------------------------------------------------------------------------------
# NeuralNetTotalError
#
# Description: After presentation of the complete set of training samples to the network
# during training, the network computes the total error corresponding to this whole set. A 
# threshold for this error is set to decide when the training should be terminated.
# 
# Valid value: Any real number from 0-1
# Default value: 0.00001
#-------------------------------------------------------------------------------
NeuralNetTotalError = 0.00001

#-------------------------------------------------------------------------------
# NeuralNetIndividualError
#
# Description: After each presentation of a training sample to the network during its
# training the system calculates the error value for the particular sample. A threshold 
# for this error is set to decide when the training should be terminated.
# 
# Valid value: Any real number from 0-1
# Default value: 0.00001
#-------------------------------------------------------------------------------
NeuralNetIndividualError = 0.00001

#-------------------------------------------------------------------------------
# NeuralNetHiddenLayersSize
#
# Description: In a full-connected, feed-forward, perceptron neural network the values 
#only move from input to hidden to output layers. All neural networks have an input layer 
#and an output layer, but the number of hidden layers may vary. When there is more than 
#one hidden layer, the output from one hidden layer is fed into the next hidden layer 
#and separate weights are applied to the sum going into each layer. For nearly all problems, 
#one hidden layer is sufficient. Two hidden layers may be helpful in a few cases such as 
#modeling data with discontinuities, e.g., a saw tooth wave pattern. Using two hidden layers 
#rarely improves the model, and it may introduce a greater risk of converging to a local 
#minima. There is no theoretical reason for using more than two hidden layers.  Three layer 
#models with one hidden layer are recommended. 
# 
# Valid value: [any integer from 1-50]
# Default value: 1
#-------------------------------------------------------------------------------
NeuralNetHiddenLayersSize = 1

#-------------------------------------------------------------------------------
# NeuralNetHiddenLayersUnitSize
#
# Description: One of the important issues of a MLP network is the choice of number of neurons 
# in the hidden layer(s). An inadequate number of neurons causes failure to model complex data, 
# and the final result is bound to be poor. If too many neurons are used, the training time may 
# become excessively long, and, worse, the network may over fit the data. When overfitting occurs, 
# the network will begin to model random noise in the data. Use of a validation set helps to 
# detect overfitting. There are several approaches in the literature for automatic selection of the 
# optimal number of neurons in the hidden layer. A better approach is to build models using varying 
# numbers of hidden neurons and measure the quality of training using cross validation or hold-out 
# data not used for training. This is a highly effective method for finding the optimal number of 
# neurons, but it is computationally expensive, because many models must be built, and each model 
# has to be validated.
# 
# Valid value: [any integer]
# Default value: 175:
#-------------------------------------------------------------------------------
NeuralNetHiddenLayersUnitSize = 175:

#-------------------------------------------------------------------------------
# ReestimateNeuralnetConnectionWeights
#
# Description: Training of MLP may be done in repeated sessions. For example, during the initial
# session one may continue training for 100 iterations (presentation of the whole set of training 
# samples to the network). Check the network performance on the validation or test set. In the next 
# session the trained network may be further trained for some more iterations 
# 
# Valid value: [true | false]
# Default value: false
#-------------------------------------------------------------------------------
ReestimateNeuralnetConnectionWeights = false

#-------------------------------------------------------------------------------
# NeuralnetTraningIteration
#
# Description: The number of training iterations is another important factor and it is 
# required to be chosen suitably to get best possible performance from the network. If 
# too many iterations are performed, the training time may become excessively long, and, 
# worse, the network may overfit the data. When overfitting occurs, the network will begin 
# to model random noise in the data. Use of a validation set helps to detect overfitting. 
# 
# Valid value: [any integer]
# Default value: 600
#-------------------------------------------------------------------------------
NeuralnetTrainingIteration = 600

#-------------------------------------------------------------------------------
# PrepareTraningSequence
#
# Description: 
# 
# Valid value: [true | false]
# Default value: true
#-------------------------------------------------------------------------------
PrepareTrainingSequence = true

#-----------------------------------------
#	FEATURE EXTRACTION
#-----------------------------------------

#-------------------------------------------------------------------------------
# FeatureExtractor
#
# Description: The configuration value is used to specify the feature extraction 
# module to be used for feature extraction. The point float feature extraction 
# module extracts the x,y,cosine and sine angle features at every point of the 
# character.
#
# Valid value: [PointFloatShapeFeatureExtractor|L7ShapeFeatureExtractor|
#               NPenShapeFeatureExtractor|SubStrokeShapeFeatureExtractor]
# Default value: PointFloatShapeFeatureExtractor
#-------------------------------------------------------------------------------
FeatureExtractor=PointFloatShapeFeatureExtractor

#-----------------------------------------
#	RECOGNITION
#-----------------------------------------

#-------------------------------------------------------------------------------
# NNRecoRejectThreshold
# 
# Description: Threshold to reject the test sample. If the confidence obtained 
# for the recognition of test sample is less than this threshold then the test 
# sample is rejected. 
#
# Valid value: Any real number from 0-1
# Default value: 0.001
#-------------------------------------------------------------------------------
NNRecoRejectThreshold =0.001

#--------------------------------------------
#      COMMON FOR TRAINING AND RECOGNITION
#--------------------------------------------

#-------------------------------------------------------------------------------
# NNDTWBandingRadius
#
# Description: This configuration parameter specifies the mode for 
# opening the mdt file. 
#
# Valid values: ascii, binary
# Default Value: ascii
#-------------------------------------------------------------------------------

NNMDTFileOpenMode=ascii
